{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import prophet\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm.autonotebook import tqdm\n",
    "import shutil\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare new data to update models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>171.509995</td>\n",
       "      <td>172.539993</td>\n",
       "      <td>169.410004</td>\n",
       "      <td>169.800003</td>\n",
       "      <td>168.820221</td>\n",
       "      <td>90956700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>171.080002</td>\n",
       "      <td>165.940002</td>\n",
       "      <td>166.229996</td>\n",
       "      <td>165.270813</td>\n",
       "      <td>94815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>166.979996</td>\n",
       "      <td>169.679993</td>\n",
       "      <td>164.179993</td>\n",
       "      <td>164.509995</td>\n",
       "      <td>163.560730</td>\n",
       "      <td>91420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>164.419998</td>\n",
       "      <td>166.330002</td>\n",
       "      <td>162.300003</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>161.472839</td>\n",
       "      <td>122848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>160.020004</td>\n",
       "      <td>162.300003</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>161.619995</td>\n",
       "      <td>160.687408</td>\n",
       "      <td>162294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>130.259995</td>\n",
       "      <td>131.259995</td>\n",
       "      <td>128.119995</td>\n",
       "      <td>130.729996</td>\n",
       "      <td>130.729996</td>\n",
       "      <td>63896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>131.250000</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>130.460007</td>\n",
       "      <td>133.490005</td>\n",
       "      <td>133.490005</td>\n",
       "      <td>69458900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>133.880005</td>\n",
       "      <td>134.259995</td>\n",
       "      <td>131.440002</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>71379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>134.919998</td>\n",
       "      <td>131.660004</td>\n",
       "      <td>134.759995</td>\n",
       "      <td>134.759995</td>\n",
       "      <td>57758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>134.830002</td>\n",
       "      <td>137.289993</td>\n",
       "      <td>134.130005</td>\n",
       "      <td>135.940002</td>\n",
       "      <td>135.940002</td>\n",
       "      <td>63502900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "0   2022-01-18  171.509995  172.539993  169.410004  169.800003  168.820221   \n",
       "1   2022-01-19  170.000000  171.080002  165.940002  166.229996  165.270813   \n",
       "2   2022-01-20  166.979996  169.679993  164.179993  164.509995  163.560730   \n",
       "3   2022-01-21  164.419998  166.330002  162.300003  162.410004  161.472839   \n",
       "4   2022-01-24  160.020004  162.300003  154.699997  161.619995  160.687408   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "246 2023-01-10  130.259995  131.259995  128.119995  130.729996  130.729996   \n",
       "247 2023-01-11  131.250000  133.509995  130.460007  133.490005  133.490005   \n",
       "248 2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
       "249 2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
       "250 2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
       "\n",
       "        Volume  \n",
       "0     90956700  \n",
       "1     94815000  \n",
       "2     91420500  \n",
       "3    122848900  \n",
       "4    162294600  \n",
       "..         ...  \n",
       "246   63896200  \n",
       "247   69458900  \n",
       "248   71379600  \n",
       "249   57758000  \n",
       "250   63502900  \n",
       "\n",
       "[251 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv('./NASDAQ_100/AAPL.csv')\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "# latest_date = df_data['Date'].tail(6).values[3]\n",
    "# latest_date = ''\n",
    "# with open('./containers/update/latest_date.txt', 'r') as f:\n",
    "#     latest_date = f.readline()\n",
    "#     f.close()\n",
    "# latest_date = pd.to_datetime(latest_date)\n",
    "# new_data = df_data[df_data['Date'] > latest_date]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_IP = '91.206.15.104'\n",
    "MLFLOW_PASSWORD = 'lH19Y0ImXQNg'\n",
    "MLFLOW_USER = 'godder'\n",
    "MLFLOW_PORT = '9899'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://{}:{}'.format(MLFLOW_IP, MLFLOW_PORT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "registry_uri = mlflow.get_registry_uri()\n",
    "\n",
    "client = mlflow.MlflowClient(tracking_uri=tracking_uri, registry_uri=registry_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_name = 'AAPL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id = mlflow.create_experiment(\n",
    "#     \"Prophet update\",\n",
    "#     artifact_location=\"sftp://{}:{}@{}:/home/godder/mlflow_storage/artifacts\".format(MLFLOW_USER, MLFLOW_PASSWORD, MLFLOW_IP),\n",
    "#     tags={\"version\": \".1\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='Prophet'\"):\n",
    "    vers.append(int(mv.version))\n",
    "prophet_latest = max(vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"Prophet update\"))['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(experiment_id=exp_id, run_name='Prophet updating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godder/.local/lib/python3.8/site-packages/prophet/serialize.py:160: FutureWarning: The behavior of Timestamp.utcfromtimestamp is deprecated, in a future version will return a timezone-aware Timestamp with UTC timezone. To keep the old behavior, use Timestamp.utcfromtimestamp(ts).tz_localize(None). To get the future behavior, use Timestamp.fromtimestamp(ts, 'UTC')\n",
      "  setattr(model, attribute, pd.Timestamp.utcfromtimestamp(model_dict[attribute]).tz_localize(None))\n"
     ]
    }
   ],
   "source": [
    "old_model = mlflow.prophet.load_model(\n",
    "    model_uri=f\"models:/Prophet/{prophet_latest}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:07:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f7106678f10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model = prophet.Prophet(changepoint_prior_scale=old_model.changepoint_prior_scale, seasonality_prior_scale=old_model.seasonality_prior_scale, weekly_seasonality=old_model.weekly_seasonality)\n",
    "new_df = new_data[['Date', 'Close']].copy()\n",
    "new_df.rename({'Date': 'ds', 'Close': 'y'}, axis=1, inplace=True)\n",
    "updated_model.fit(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = updated_model.make_future_dataframe(periods=10)\n",
    "signature = mlflow.models.signature.infer_signature(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__file__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-27761c3a9533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mlflow.prophet.log_model(updated_model,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0;34m'prophet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mregistered_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prophet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          input_example=future)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/prophet.py\u001b[0m in \u001b[0;36mlog_model\u001b[0;34m(pr_model, artifact_path, conda_env, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata)\u001b[0m\n\u001b[1;32m    261\u001b[0m              \u001b[0mmetadata\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogged\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m     return Model.log(\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprophet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/models/model.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_start_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mmlflow_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0mflavor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlflow_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlflow_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/prophet.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(pr_model, path, conda_env, code_paths, mlflow_model, signature, input_example, pip_requirements, extra_pip_requirements, metadata)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mdefault_reqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         conda_env, pip_requirements, pip_constraints = _process_pip_requirements(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mdefault_reqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mpip_requirements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/utils/environment.py\u001b[0m in \u001b[0;36m_process_pip_requirements\u001b[0;34m(default_pip_requirements, pip_requirements, extra_pip_requirements)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;31m# Set `install_mlflow` to False because `pip_reqs` already contains `mlflow`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mconda_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mlflow_conda_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_pip_deps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpip_reqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstall_mlflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconda_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpip_reqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/utils/environment.py\u001b[0m in \u001b[0;36m_mlflow_conda_env\u001b[0;34m(path, additional_conda_deps, additional_pip_deps, additional_conda_channels, install_mlflow)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mconda_deps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_conda_deps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madditional_conda_deps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_deps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mpip_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_pip_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpip_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# When a new version of pip is released on PyPI, it takes a while until that version is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mlflow/utils/environment.py\u001b[0m in \u001b[0;36m_get_pip_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/_distutils_hack/__init__.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, path, target)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'spec_for_{fullname}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspec_for_distutils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/_distutils_hack/__init__.py\u001b[0m in \u001b[0;36mspec_for_pip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mpypa\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpip\u001b[0m\u001b[0;31m#8761 for rationale.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpip_imported_during_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mclear_distutils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/_distutils_hack/__init__.py\u001b[0m in \u001b[0;36mpip_imported_during_build\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         return any(\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__file__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setup.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/_distutils_hack/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         return any(\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__file__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setup.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         )\n",
      "\u001b[0;31mKeyError\u001b[0m: '__file__'"
     ]
    }
   ],
   "source": [
    "mlflow.prophet.log_model(updated_model,\n",
    "                         'prophet',\n",
    "                         registered_model_name='Prophet',\n",
    "                         signature=signature,\n",
    "                         input_example=future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "version = prophet_latest + 1\n",
    "client.transition_model_version_stage(\n",
    "    name=\"Prophet\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"Prophet\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or move each class and func to another file and make imports for beauty.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Special dataset class for training transformer neural network on stock prices data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, indices, enc_seq_len,\n",
    "                 dec_seq_len, target_seq_len, normalize=False):\n",
    "        \"\"\"\n",
    "        Constructor for dataset class\n",
    "        Args:\n",
    "            data: pd.DataFrame. Data to work with\n",
    "            indices: list of tuples of indices, marking starting and ending of subsequences\n",
    "            enc_seq_len: sequence length for encoder\n",
    "            dec_seq_len: sequence length for decode\n",
    "            target_seq_len: sequence length of target\n",
    "            normalize: whether to normalize data by columns or not\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.indices = indices\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "        if normalize:\n",
    "            self.data = (self.data-self.data.mean())/self.data.std()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get length of dataset class\n",
    "        Returns: length of dataset\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get tuple: [src, trg, trg_y]\n",
    "\n",
    "        Args:\n",
    "            index: int, index to get item\n",
    "        \"\"\"\n",
    "        starting_index = self.indices[index][0]\n",
    "        ending_index = self.indices[index][1]\n",
    "        \n",
    "        sequence = self.data[starting_index:ending_index]\n",
    "        \n",
    "        return self.get_src_trg(sequence)\n",
    "        \n",
    "    def get_src_trg(self, sequence):\n",
    "        \"\"\"\n",
    "        Get source, target, and ground truth from sequence, that's input of Transformer class.\n",
    "        Args:\n",
    "            sequence: sequence to divide\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        assert(len(sequence)==self.dec_seq_len+self.target_seq_len)\n",
    "        \n",
    "        src = sequence[:self.enc_seq_len]\n",
    "        trg = sequence[self.enc_seq_len-1:len(sequence)-1]\n",
    "        \n",
    "        assert(len(trg) == self.target_seq_len)\n",
    "        trg_y = sequence[-self.target_seq_len:]\n",
    "        \n",
    "        assert(len(trg_y) == self.target_seq_len)\n",
    "        src = torch.tensor(src.values.astype(np.float32))\n",
    "        trg = torch.tensor(trg.values.astype(np.float32))\n",
    "        trg_y = torch.tensor(trg_y.values.astype(np.float32))\n",
    "        return src, trg, trg_y\n",
    "    \n",
    "def get_src_trg(self, sequence, enc_seq_len, target_seq_len):\n",
    "        \"\"\"\n",
    "        Get tuples of source, target and ground truth for Transformer neural network\n",
    "        Args:\n",
    "            sequence: sequence to split\n",
    "            enc_seq_len: length of encoder sequence\n",
    "            target_seq_len: length of decoder sequence\n",
    "\n",
    "        Returns: tuple, containing source, target and ground truth\n",
    "        \"\"\"\n",
    "        assert (len(sequence) == enc_seq_len + target_seq_len)\n",
    "        \n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "\n",
    "        trg = trg[:, 0]\n",
    "\n",
    "        if len(trg.shape) == 1:\n",
    "            trg = trg.unsqueeze(-1)\n",
    "        \n",
    "        assert (len(trg) == target_seq_len)\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "\n",
    "        trg_y = trg_y[:, 0]\n",
    "        \n",
    "        assert (len(trg_y) == target_seq_len)\n",
    "\n",
    "        return src, trg, trg_y.squeeze(-1)\n",
    "    \n",
    "def get_indices_entire_sequence(data: pd.DataFrame, window_size, step_size):\n",
    "        \"\"\"\n",
    "        Split data to indices for Transformer neural network learning\n",
    "        Args:\n",
    "            data: data to split\n",
    "            window_size: size of sliding window (aka seq length)\n",
    "            step_size: how many values to skip in each iteration\n",
    "\n",
    "        Returns:\n",
    "            list of indices\n",
    "        \"\"\"\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"CompatibleTransformer\"))['experiment_id']\n",
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done!\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(exp_id)\n",
    "run_id = runs.where(runs['status'] == 'FINISHED').dropna().sort_values(by='end_time', ascending=False).iloc[0].run_id\n",
    "if not os.path.exists('temp/'):\n",
    "    os.mkdir('temp')\n",
    "mlflow.artifacts.download_artifacts(run_id=run_id, dst_path='temp')\n",
    "print ('...done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "dec_seq_len = 50\n",
    "enc_seq_len = 50\n",
    "output_sequence_length = 10\n",
    "window_size = enc_seq_len+output_sequence_length\n",
    "max_seq_len = enc_seq_len \n",
    "normalize = True\n",
    "dropout_probability = .2\n",
    "n_epochs = 40\n",
    "DEVICE = 'cpu'\n",
    "lr=2e-5\n",
    "\n",
    "transformer_data = new_data.drop(columns=['Date'])\n",
    "training_indices = get_indices_entire_sequence(transformer_data, window_size, 1)\n",
    "training_dataset = TransformerDataset(transformer_data,\n",
    "                                      training_indices,\n",
    "                                      enc_seq_len,\n",
    "                                      dec_seq_len,\n",
    "                                      output_sequence_length,\n",
    "                                      normalize=normalize)\n",
    "\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size)\n",
    "\n",
    "m = torch.load('temp/transformer.pth/data/model.pth')\n",
    "m.train()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id,\n",
    "                      run_name=\"Transformer update\"):\n",
    "    mlflow.set_tag('ticker', 'AAPL')\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):    \n",
    "        train_epoch_losses = []\n",
    "\n",
    "        for src, trg, trg_y in training_dataloader:\n",
    "            src = src.to(device=DEVICE)\n",
    "            trg = trg.to(device=DEVICE)\n",
    "            trg_y = trg_y.to(device=DEVICE)[:, :, 3].unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            trg_y = trg_y.permute(1, 0, 2)\n",
    "            output = model.inner_forward(src, trg)\n",
    "            loss = criterion(output, trg_y)\n",
    "        \n",
    "            train_epoch_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", np.mean(train_epoch_losses), step=epoch)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {np.mean(train_epoch_losses):.4f}')\n",
    "    signature = mlflow.models.signature.infer_signature(np.array(torch.tensor(transformer_data.values).numpy()).astype(np.float64))\n",
    "    \n",
    "    mlflow.pytorch.log_model(model,\n",
    "             'transformer.pth',\n",
    "             registered_model_name='CompatibleTransformer',\n",
    "             signature = signature,\n",
    "             input_example = np.array(torch.tensor(transformer_data.values).numpy())\n",
    "             )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='CompatibleTransformer'\"):\n",
    "    vers.append(int(mv.version))\n",
    "version = max(vers)\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"CompatibleTransformer\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"CompatibleTransformer\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "\n",
    "shutil.rmtree('temp/')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id = mlflow.create_experiment(\n",
    "#     \"ARIMA update\",\n",
    "#     artifact_location=\"sftp://{}:{}@{}:/home/godder/mlflow_storage/artifacts\".format(MLFLOW_USER, MLFLOW_PASSWORD, MLFLOW_IP),\n",
    "#     tags={\"version\": \".1\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='ARIMA'\"):\n",
    "    vers.append(int(mv.version))\n",
    "arima_latest = max(vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"ARIMA update\"))['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(experiment_id=exp_id, run_name='ARIMA updating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df  = new_data[['Date','Close']].copy()\n",
    "new_df['Close'] = np.log(new_df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = mlflow.pmdarima.load_model(\n",
    "    model_uri=f\"models:/ARIMA/{arima_latest}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ARIMA(new_df['Close'], order=old_model.order)\n",
    "updated_model = new_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pmdarima.auto_arima(new_df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mlflow/models/signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n"
     ]
    }
   ],
   "source": [
    "signature = mlflow.models.signature.infer_signature(pd.DataFrame([{\"n_periods\": 10, \"return_conf_int\": True, \"alpha\": 0.1}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ARIMA' already exists. Creating a new version of this model...\n",
      "2023/01/19 20:33:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ARIMA, version 9\n",
      "Created version '9' of model 'ARIMA'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f6a06c20070>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pmdarima.log_model(m, 'ARIMA', registered_model_name='ARIMA',\n",
    "                         signature=signature,\n",
    "                         input_example=pd.DataFrame([{\"n_periods\": 10, \"return_conf_int\": True, \"alpha\": 0.1}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "version = arima_latest + 1\n",
    "client.transition_model_version_stage(\n",
    "    name=\"ARIMA\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"ARIMA\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
