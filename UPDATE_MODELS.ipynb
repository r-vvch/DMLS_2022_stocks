{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import prophet\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm.autonotebook import tqdm\n",
    "import shutil\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare new data to update models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>171.080002</td>\n",
       "      <td>165.940002</td>\n",
       "      <td>166.229996</td>\n",
       "      <td>165.270813</td>\n",
       "      <td>94815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>166.979996</td>\n",
       "      <td>169.679993</td>\n",
       "      <td>164.179993</td>\n",
       "      <td>164.509995</td>\n",
       "      <td>163.560730</td>\n",
       "      <td>91420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>164.419998</td>\n",
       "      <td>166.330002</td>\n",
       "      <td>162.300003</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>161.472855</td>\n",
       "      <td>122848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>160.020004</td>\n",
       "      <td>162.300003</td>\n",
       "      <td>154.699997</td>\n",
       "      <td>161.619995</td>\n",
       "      <td>160.687393</td>\n",
       "      <td>162294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>158.979996</td>\n",
       "      <td>162.759995</td>\n",
       "      <td>157.020004</td>\n",
       "      <td>159.779999</td>\n",
       "      <td>158.858032</td>\n",
       "      <td>115798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>133.880005</td>\n",
       "      <td>134.259995</td>\n",
       "      <td>131.440002</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>71379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>134.919998</td>\n",
       "      <td>131.660004</td>\n",
       "      <td>134.759995</td>\n",
       "      <td>134.759995</td>\n",
       "      <td>57758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>134.830002</td>\n",
       "      <td>137.289993</td>\n",
       "      <td>134.130005</td>\n",
       "      <td>135.940002</td>\n",
       "      <td>135.940002</td>\n",
       "      <td>63646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>136.820007</td>\n",
       "      <td>138.610001</td>\n",
       "      <td>135.029999</td>\n",
       "      <td>135.210007</td>\n",
       "      <td>135.210007</td>\n",
       "      <td>69567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>135.317795</td>\n",
       "      <td>133.880005</td>\n",
       "      <td>134.589996</td>\n",
       "      <td>134.589996</td>\n",
       "      <td>14972121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "0   2022-01-19  170.000000  171.080002  165.940002  166.229996  165.270813   \n",
       "1   2022-01-20  166.979996  169.679993  164.179993  164.509995  163.560730   \n",
       "2   2022-01-21  164.419998  166.330002  162.300003  162.410004  161.472855   \n",
       "3   2022-01-24  160.020004  162.300003  154.699997  161.619995  160.687393   \n",
       "4   2022-01-25  158.979996  162.759995  157.020004  159.779999  158.858032   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "247 2023-01-12  133.880005  134.259995  131.440002  133.410004  133.410004   \n",
       "248 2023-01-13  132.029999  134.919998  131.660004  134.759995  134.759995   \n",
       "249 2023-01-17  134.830002  137.289993  134.130005  135.940002  135.940002   \n",
       "250 2023-01-18  136.820007  138.610001  135.029999  135.210007  135.210007   \n",
       "251 2023-01-19  134.080002  135.317795  133.880005  134.589996  134.589996   \n",
       "\n",
       "        Volume  \n",
       "0     94815000  \n",
       "1     91420500  \n",
       "2    122848900  \n",
       "3    162294600  \n",
       "4    115798400  \n",
       "..         ...  \n",
       "247   71379600  \n",
       "248   57758000  \n",
       "249   63646600  \n",
       "250   69567000  \n",
       "251   14972121  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv('./data/NASDAQ_100/AAPL.csv')\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_IP = os.environ['MLFLOW_IP']\n",
    "MLFLOW_PASSWORD = os.environ['MLFLOW_PASSWORD']\n",
    "MLFLOW_USER = os.environ['MLFLOW_USER']\n",
    "MLFLOW_PORT = os.environ['MLFLOW_PORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://{}:{}'.format(MLFLOW_IP, MLFLOW_PORT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "registry_uri = mlflow.get_registry_uri()\n",
    "\n",
    "client = mlflow.MlflowClient(tracking_uri=tracking_uri, registry_uri=registry_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_name = 'AAPL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='Prophet'\"):\n",
    "    vers.append(int(mv.version))\n",
    "prophet_latest = max(vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"Prophet\"))['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(experiment_id=exp_id, run_name='Prophet updating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = mlflow.prophet.load_model(\n",
    "    model_uri=f\"models:/Prophet/{prophet_latest}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:04:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:04:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f40f307da00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model = prophet.Prophet(changepoint_prior_scale=old_model.changepoint_prior_scale, seasonality_prior_scale=old_model.seasonality_prior_scale, weekly_seasonality=old_model.weekly_seasonality)\n",
    "new_df = new_data[['Date', 'Close']].copy()\n",
    "new_df.rename({'Date': 'ds', 'Close': 'y'}, axis=1, inplace=True)\n",
    "updated_model.fit(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = updated_model.make_future_dataframe(periods=10)\n",
    "signature = mlflow.models.signature.infer_signature(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Prophet' already exists. Creating a new version of this model...\n",
      "2023/01/20 04:04:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Prophet, version 26\n",
      "Created version '26' of model 'Prophet'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f411c42ca60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.prophet.log_model(updated_model,\n",
    "                         'prophet',\n",
    "                         registered_model_name='Prophet',\n",
    "                         signature=signature,\n",
    "                         input_example=future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "version = prophet_latest + 1\n",
    "client.transition_model_version_stage(\n",
    "    name=\"Prophet\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"Prophet\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/20 04:04:21 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2023/01/20 04:04:22 INFO mlflow.models.docker_utils: Building docker image with name prophet-image\n",
      "Sending build context to Docker daemon  67.58kB\n",
      "\n",
      "Step 1/28 : FROM ubuntu:20.04\n",
      " ---> d5447fc01ae6\n",
      "Step 2/28 : RUN apt-get -y update\n",
      " ---> Using cache\n",
      " ---> d229c6e16920\n",
      "Step 3/28 : RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 84dec3c1ab75\n",
      "Step 4/28 : RUN apt -y update\n",
      " ---> Using cache\n",
      " ---> 824a7c42886e\n",
      "Step 5/28 : RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get -y install tzdata\n",
      " ---> Using cache\n",
      " ---> 13517bdbf4e3\n",
      "Step 6/28 : RUN apt-get install -y     libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm     libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev\n",
      " ---> Using cache\n",
      " ---> 4deb50f73700\n",
      "Step 7/28 : RUN git clone     --depth 1     --branch $(git ls-remote --tags https://github.com/pyenv/pyenv.git | grep -o -E 'v[1-9]+(\\.[1-9]+)+$' | tail -1)     https://github.com/pyenv/pyenv.git /root/.pyenv\n",
      " ---> Using cache\n",
      " ---> 00c4ec59b3f4\n",
      "Step 8/28 : ENV PYENV_ROOT=\"/root/.pyenv\"\n",
      " ---> Using cache\n",
      " ---> fb8b80040414\n",
      "Step 9/28 : ENV PATH=\"$PYENV_ROOT/bin:$PATH\"\n",
      " ---> Using cache\n",
      " ---> 13a89d3f013c\n",
      "Step 10/28 : RUN apt install -y python3.8 python3.8-distutils\n",
      " ---> Using cache\n",
      " ---> fa1095b23761\n",
      "Step 11/28 : RUN ln -s -f $(which python3.8) /usr/bin/python\n",
      " ---> Using cache\n",
      " ---> f7ccb88fc9d2\n",
      "Step 12/28 : RUN wget https://bootstrap.pypa.io/get-pip.py -O /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> 39216e8a992e\n",
      "Step 13/28 : RUN python /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> e2db0c8cbb46\n",
      "Step 14/28 : RUN pip install virtualenv\n",
      " ---> Using cache\n",
      " ---> 572c8551d7c0\n",
      "Step 15/28 : ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      " ---> Using cache\n",
      " ---> 1cd85ac72cb3\n",
      "Step 16/28 : ENV GUNICORN_CMD_ARGS=\"--timeout 60 -k gevent\"\n",
      " ---> Using cache\n",
      " ---> ca97e25a915d\n",
      "Step 17/28 : WORKDIR /opt/mlflow\n",
      " ---> Using cache\n",
      " ---> f6519b8b4baa\n",
      "Step 18/28 : RUN pip install mlflow==2.1.1\n",
      " ---> Using cache\n",
      " ---> cf0a340a7fd0\n",
      "Step 19/28 : RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.1.1:pom -DoutputDirectory=/opt/java\n",
      " ---> Using cache\n",
      " ---> 56668933c965\n",
      "Step 20/28 : RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.1.1:jar -DoutputDirectory=/opt/java/jars\n",
      " ---> Using cache\n",
      " ---> 0654e18d21e3\n",
      "Step 21/28 : RUN cp /opt/java/mlflow-scoring-2.1.1.pom /opt/java/pom.xml\n",
      " ---> Using cache\n",
      " ---> 0776f1409768\n",
      "Step 22/28 : RUN cd /opt/java && mvn --batch-mode dependency:copy-dependencies -DoutputDirectory=/opt/java/jars\n",
      " ---> Using cache\n",
      " ---> d466c6de631c\n",
      "Step 23/28 : COPY model_dir/ /opt/ml/model\n",
      " ---> 9b9680569718\n",
      "Step 24/28 : RUN python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        \"/opt/ml/model\",                         install_mlflow=False,                         enable_mlserver=False,                         env_manager=\"virtualenv\")'\n",
      " ---> Running in 471c7886fbb9\n",
      "\u001b[91m2023/01/20 01:04:24 INFO mlflow.models.container: creating and activating custom environment\n",
      "\u001b[0m\u001b[91m2023/01/20 01:04:24 INFO mlflow.utils.virtualenv: Installing python 3.8.10 if it does not exist\n",
      "\u001b[0m\u001b[91mDownloading Python-3.8.10.tar.xz...\n",
      "\u001b[0m\u001b[91m-> https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tar.xz\n",
      "\u001b[0m\u001b[91mInstalling Python-3.8.10...\n",
      "\u001b[0mpatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\n",
      "patching file configure\n",
      "patching file configure.ac\n",
      "\u001b[91mInstalled Python-3.8.10 to /root/.pyenv/versions/3.8.10\n",
      "\n",
      "\u001b[0m\u001b[91m2023/01/20 01:05:39 INFO mlflow.utils.virtualenv: Creating a new environment /root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b\n",
      "\u001b[0mcreated virtual environment CPython3.8.10.final.0-64 in 458ms\n",
      "  creator CPython3Posix(dest=/root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b, clear=False, no_vcs_ignore=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
      "    added seed packages: pip==22.3.1, setuptools==65.6.3, wheel==0.38.4\n",
      "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
      "\u001b[91m2023/01/20 01:05:40 INFO mlflow.utils.virtualenv: Installing dependencies\n",
      "\u001b[0m\u001b[91mERROR: numba 0.56.4 has requirement numpy<1.24,>=1.18, but you'll have numpy 1.24.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 20.0.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRequirement already satisfied: gunicorn[gevent] in /root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b/lib/python3.8/site-packages (20.1.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b/lib/python3.8/site-packages (from gunicorn[gevent]) (45.2.0)\n",
      "Collecting gevent>=1.4.0; extra == \"gevent\"\n",
      "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
      "Requirement already satisfied: greenlet>=2.0.0; platform_python_implementation == \"CPython\" in /root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b/lib/python3.8/site-packages (from gevent>=1.4.0; extra == \"gevent\"->gunicorn[gevent]) (2.0.1)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: zope.interface, zope.event, gevent\n",
      "Successfully installed gevent-22.10.2 zope.event-4.6 zope.interface-5.5.2\n",
      "\u001b[91mWARNING: You are using pip version 20.0.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/.mlflow/envs/mlflow-5c50a0c6e12598d7608acaca3b5e3c17214a283b/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 471c7886fbb9\n",
      " ---> 7b31a3411b52\n",
      "Step 25/28 : ENV MLFLOW_DISABLE_ENV_CREATION=\"true\"\n",
      " ---> Running in e2d445c8db6e\n",
      "Removing intermediate container e2d445c8db6e\n",
      " ---> ec576fc236af\n",
      "Step 26/28 : ENV ENABLE_MLSERVER=False\n",
      " ---> Running in 99560d2d6948\n",
      "Removing intermediate container 99560d2d6948\n",
      " ---> 904b1b7175e0\n",
      "Step 27/28 : RUN chmod o+rwX /opt/mlflow/\n",
      " ---> Running in d53c6fd5e1e3\n",
      "Removing intermediate container d53c6fd5e1e3\n",
      " ---> 7a309ee65500\n",
      "Step 28/28 : ENTRYPOINT [\"python\", \"-c\", \"from mlflow.models import container as C;C._serve('virtualenv')\"]\n",
      " ---> Running in eff94d04d3f6\n",
      "Removing intermediate container eff94d04d3f6\n",
      " ---> 2779a26a2a84\n",
      "Successfully built 2779a26a2a84\n",
      "Successfully tagged prophet-image:latest\n"
     ]
    }
   ],
   "source": [
    "mlflow.models.build_docker(f\"models:/Prophet/{version}\", name='prophet-image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or move each class and func to another file and make imports for beauty.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Special dataset class for training transformer neural network on stock prices data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, indices, enc_seq_len,\n",
    "                 dec_seq_len, target_seq_len, normalize=False):\n",
    "        \"\"\"\n",
    "        Constructor for dataset class\n",
    "        Args:\n",
    "            data: pd.DataFrame. Data to work with\n",
    "            indices: list of tuples of indices, marking starting and ending of subsequences\n",
    "            enc_seq_len: sequence length for encoder\n",
    "            dec_seq_len: sequence length for decode\n",
    "            target_seq_len: sequence length of target\n",
    "            normalize: whether to normalize data by columns or not\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.indices = indices\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "        if normalize:\n",
    "            self.data = (self.data-self.data.mean())/self.data.std()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get length of dataset class\n",
    "        Returns: length of dataset\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get tuple: [src, trg, trg_y]\n",
    "\n",
    "        Args:\n",
    "            index: int, index to get item\n",
    "        \"\"\"\n",
    "        starting_index = self.indices[index][0]\n",
    "        ending_index = self.indices[index][1]\n",
    "        \n",
    "        sequence = self.data[starting_index:ending_index]\n",
    "        \n",
    "        return self.get_src_trg(sequence)\n",
    "        \n",
    "    def get_src_trg(self, sequence):\n",
    "        \"\"\"\n",
    "        Get source, target, and ground truth from sequence, that's input of Transformer class.\n",
    "        Args:\n",
    "            sequence: sequence to divide\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        assert(len(sequence)==self.dec_seq_len+self.target_seq_len)\n",
    "        \n",
    "        src = sequence[:self.enc_seq_len]\n",
    "        trg = sequence[self.enc_seq_len-1:len(sequence)-1]\n",
    "        \n",
    "        assert(len(trg) == self.target_seq_len)\n",
    "        trg_y = sequence[-self.target_seq_len:]\n",
    "        \n",
    "        assert(len(trg_y) == self.target_seq_len)\n",
    "        src = torch.tensor(src.values.astype(np.float32))\n",
    "        trg = torch.tensor(trg.values.astype(np.float32))\n",
    "        trg_y = torch.tensor(trg_y.values.astype(np.float32))\n",
    "        return src, trg, trg_y\n",
    "    \n",
    "def get_src_trg(self, sequence, enc_seq_len, target_seq_len):\n",
    "        \"\"\"\n",
    "        Get tuples of source, target and ground truth for Transformer neural network\n",
    "        Args:\n",
    "            sequence: sequence to split\n",
    "            enc_seq_len: length of encoder sequence\n",
    "            target_seq_len: length of decoder sequence\n",
    "\n",
    "        Returns: tuple, containing source, target and ground truth\n",
    "        \"\"\"\n",
    "        assert (len(sequence) == enc_seq_len + target_seq_len)\n",
    "        \n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "\n",
    "        trg = trg[:, 0]\n",
    "\n",
    "        if len(trg.shape) == 1:\n",
    "            trg = trg.unsqueeze(-1)\n",
    "        \n",
    "        assert (len(trg) == target_seq_len)\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "\n",
    "        trg_y = trg_y[:, 0]\n",
    "        \n",
    "        assert (len(trg_y) == target_seq_len)\n",
    "\n",
    "        return src, trg, trg_y.squeeze(-1)\n",
    "    \n",
    "def get_indices_entire_sequence(data: pd.DataFrame, window_size, step_size):\n",
    "        \"\"\"\n",
    "        Split data to indices for Transformer neural network learning\n",
    "        Args:\n",
    "            data: data to split\n",
    "            window_size: size of sliding window (aka seq length)\n",
    "            step_size: how many values to skip in each iteration\n",
    "\n",
    "        Returns:\n",
    "            list of indices\n",
    "        \"\"\"\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"CompatibleTransformer\"))['experiment_id']\n",
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done!\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(exp_id)\n",
    "run_id = runs.where(runs['status'] == 'FINISHED').dropna().sort_values(by='end_time', ascending=False).iloc[0].run_id\n",
    "if not os.path.exists('temp/'):\n",
    "    os.mkdir('temp')\n",
    "mlflow.artifacts.download_artifacts(run_id=run_id, dst_path='temp')\n",
    "print ('...done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "dec_seq_len = 50\n",
    "enc_seq_len = 50\n",
    "output_sequence_length = 10\n",
    "window_size = enc_seq_len+output_sequence_length\n",
    "max_seq_len = enc_seq_len \n",
    "normalize = True\n",
    "dropout_probability = .2\n",
    "n_epochs = 40\n",
    "DEVICE = 'cpu'\n",
    "lr=2e-5\n",
    "\n",
    "transformer_data = new_data.drop(columns=['Date'])\n",
    "training_indices = get_indices_entire_sequence(transformer_data, window_size, 1)\n",
    "training_dataset = TransformerDataset(transformer_data,\n",
    "                                      training_indices,\n",
    "                                      enc_seq_len,\n",
    "                                      dec_seq_len,\n",
    "                                      output_sequence_length,\n",
    "                                      normalize=normalize)\n",
    "\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size)\n",
    "\n",
    "m = torch.load('temp/transformer.pth/data/model.pth')\n",
    "m.train()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id,\n",
    "                      run_name=\"Transformer update\"):\n",
    "    mlflow.set_tag('ticker', 'AAPL')\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):    \n",
    "        train_epoch_losses = []\n",
    "\n",
    "        for src, trg, trg_y in training_dataloader:\n",
    "            src = src.to(device=DEVICE)\n",
    "            trg = trg.to(device=DEVICE)\n",
    "            trg_y = trg_y.to(device=DEVICE)[:, :, 3].unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            trg_y = trg_y.permute(1, 0, 2)\n",
    "            output = model.inner_forward(src, trg)\n",
    "            loss = criterion(output, trg_y)\n",
    "        \n",
    "            train_epoch_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", np.mean(train_epoch_losses), step=epoch)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {np.mean(train_epoch_losses):.4f}')\n",
    "    signature = mlflow.models.signature.infer_signature(np.array(torch.tensor(transformer_data.values).numpy()).astype(np.float64))\n",
    "    \n",
    "    mlflow.pytorch.log_model(model,\n",
    "             'transformer.pth',\n",
    "             registered_model_name='CompatibleTransformer',\n",
    "             signature = signature,\n",
    "             input_example = np.array(torch.tensor(transformer_data.values).numpy())\n",
    "             )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='CompatibleTransformer'\"):\n",
    "    vers.append(int(mv.version))\n",
    "version = max(vers)\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"CompatibleTransformer\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"CompatibleTransformer\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "\n",
    "shutil.rmtree('temp/')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.build_docker(f\"models:/CompatibleTransformer/{version}\", name='transformer-image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = []\n",
    "for mv in client.search_model_versions(\"name='ARIMA'\"):\n",
    "    vers.append(int(mv.version))\n",
    "arima_latest = max(vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = dict(mlflow.get_experiment_by_name(\"ARIMA\"))['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "print(\"Set experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(experiment_id=exp_id, run_name='ARIMA updating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df  = new_data[['Date','Close']].copy()\n",
    "new_df['Close'] = np.log(new_df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = mlflow.pmdarima.load_model(\n",
    "    model_uri=f\"models:/ARIMA/{arima_latest}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ARIMA(new_df['Close'], order=old_model.order)\n",
    "updated_model = new_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pmdarima.auto_arima(new_df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = mlflow.models.signature.infer_signature(pd.DataFrame([{\"n_periods\": 10, \"return_conf_int\": True, \"alpha\": 0.1}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ARIMA' already exists. Creating a new version of this model...\n",
      "2023/01/20 04:07:05 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ARIMA, version 14\n",
      "Created version '14' of model 'ARIMA'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f4056fd7ee0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pmdarima.log_model(m, 'ARIMA', registered_model_name='ARIMA',\n",
    "                         signature=signature,\n",
    "                         input_example=pd.DataFrame([{\"n_periods\": 10, \"return_conf_int\": True, \"alpha\": 0.1}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "version = arima_latest + 1\n",
    "client.transition_model_version_stage(\n",
    "    name=\"ARIMA\",\n",
    "    version=version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "for ver in range(1, version):\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"ARIMA\",\n",
    "        version=ver,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/20 04:07:06 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2023/01/20 04:07:07 INFO mlflow.models.docker_utils: Building docker image with name arima-image\n",
      "Sending build context to Docker daemon  373.8kB\n",
      "\n",
      "Step 1/28 : FROM ubuntu:20.04\n",
      " ---> d5447fc01ae6\n",
      "Step 2/28 : RUN apt-get -y update\n",
      " ---> Using cache\n",
      " ---> d229c6e16920\n",
      "Step 3/28 : RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get install -y --no-install-recommends          wget          curl          nginx          ca-certificates          bzip2          build-essential          cmake          openjdk-8-jdk          git-core          maven     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 84dec3c1ab75\n",
      "Step 4/28 : RUN apt -y update\n",
      " ---> Using cache\n",
      " ---> 824a7c42886e\n",
      "Step 5/28 : RUN DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get -y install tzdata\n",
      " ---> Using cache\n",
      " ---> 13517bdbf4e3\n",
      "Step 6/28 : RUN apt-get install -y     libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm     libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev\n",
      " ---> Using cache\n",
      " ---> 4deb50f73700\n",
      "Step 7/28 : RUN git clone     --depth 1     --branch $(git ls-remote --tags https://github.com/pyenv/pyenv.git | grep -o -E 'v[1-9]+(\\.[1-9]+)+$' | tail -1)     https://github.com/pyenv/pyenv.git /root/.pyenv\n",
      " ---> Using cache\n",
      " ---> 00c4ec59b3f4\n",
      "Step 8/28 : ENV PYENV_ROOT=\"/root/.pyenv\"\n",
      " ---> Using cache\n",
      " ---> fb8b80040414\n",
      "Step 9/28 : ENV PATH=\"$PYENV_ROOT/bin:$PATH\"\n",
      " ---> Using cache\n",
      " ---> 13a89d3f013c\n",
      "Step 10/28 : RUN apt install -y python3.8 python3.8-distutils\n",
      " ---> Using cache\n",
      " ---> fa1095b23761\n",
      "Step 11/28 : RUN ln -s -f $(which python3.8) /usr/bin/python\n",
      " ---> Using cache\n",
      " ---> f7ccb88fc9d2\n",
      "Step 12/28 : RUN wget https://bootstrap.pypa.io/get-pip.py -O /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> 39216e8a992e\n",
      "Step 13/28 : RUN python /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> e2db0c8cbb46\n",
      "Step 14/28 : RUN pip install virtualenv\n",
      " ---> Using cache\n",
      " ---> 572c8551d7c0\n",
      "Step 15/28 : ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
      " ---> Using cache\n",
      " ---> 1cd85ac72cb3\n",
      "Step 16/28 : ENV GUNICORN_CMD_ARGS=\"--timeout 60 -k gevent\"\n",
      " ---> Using cache\n",
      " ---> ca97e25a915d\n",
      "Step 17/28 : WORKDIR /opt/mlflow\n",
      " ---> Using cache\n",
      " ---> f6519b8b4baa\n",
      "Step 18/28 : RUN pip install mlflow==2.1.1\n",
      " ---> Using cache\n",
      " ---> cf0a340a7fd0\n",
      "Step 19/28 : RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.1.1:pom -DoutputDirectory=/opt/java\n",
      " ---> Using cache\n",
      " ---> 56668933c965\n",
      "Step 20/28 : RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.1.1:jar -DoutputDirectory=/opt/java/jars\n",
      " ---> Using cache\n",
      " ---> 0654e18d21e3\n",
      "Step 21/28 : RUN cp /opt/java/mlflow-scoring-2.1.1.pom /opt/java/pom.xml\n",
      " ---> Using cache\n",
      " ---> 0776f1409768\n",
      "Step 22/28 : RUN cd /opt/java && mvn --batch-mode dependency:copy-dependencies -DoutputDirectory=/opt/java/jars\n",
      " ---> Using cache\n",
      " ---> d466c6de631c\n",
      "Step 23/28 : COPY model_dir/ /opt/ml/model\n",
      " ---> f74530a84ecd\n",
      "Step 24/28 : RUN python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        \"/opt/ml/model\",                         install_mlflow=False,                         enable_mlserver=False,                         env_manager=\"virtualenv\")'\n",
      " ---> Running in ba501807a65e\n",
      "\u001b[91m2023/01/20 01:07:08 INFO mlflow.models.container: creating and activating custom environment\n",
      "\u001b[0m\u001b[91m2023/01/20 01:07:08 INFO mlflow.utils.virtualenv: Installing python 3.8.10 if it does not exist\n",
      "\u001b[0m\u001b[91mDownloading Python-3.8.10.tar.xz...\n",
      "\u001b[0m\u001b[91m-> https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tar.xz\n",
      "\u001b[0m\u001b[91mInstalling Python-3.8.10...\n",
      "\u001b[0mpatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\n",
      "patching file configure\n",
      "patching file configure.ac\n",
      "\u001b[91mInstalled Python-3.8.10 to /root/.pyenv/versions/3.8.10\n",
      "\n",
      "\u001b[0m\u001b[91m2023/01/20 01:08:24 INFO mlflow.utils.virtualenv: Creating a new environment /root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7\n",
      "\u001b[0mcreated virtual environment CPython3.8.10.final.0-64 in 477ms\n",
      "  creator CPython3Posix(dest=/root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7, clear=False, no_vcs_ignore=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
      "    added seed packages: pip==22.3.1, setuptools==65.6.3, wheel==0.38.4\n",
      "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
      "\u001b[91m2023/01/20 01:08:25 INFO mlflow.utils.virtualenv: Installing dependencies\n",
      "\u001b[0m\u001b[91mERROR: numba 0.56.4 has requirement numpy<1.24,>=1.18, but you'll have numpy 1.24.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 20.0.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRequirement already satisfied: gunicorn[gevent] in /root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7/lib/python3.8/site-packages (20.1.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7/lib/python3.8/site-packages (from gunicorn[gevent]) (45.2.0)\n",
      "Collecting gevent>=1.4.0; extra == \"gevent\"\n",
      "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
      "Requirement already satisfied: greenlet>=2.0.0; platform_python_implementation == \"CPython\" in /root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7/lib/python3.8/site-packages (from gevent>=1.4.0; extra == \"gevent\"->gunicorn[gevent]) (2.0.1)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: zope.interface, zope.event, gevent\n",
      "Successfully installed gevent-22.10.2 zope.event-4.6 zope.interface-5.5.2\n",
      "\u001b[91mWARNING: You are using pip version 20.0.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/.mlflow/envs/mlflow-49e15ead0724bc3c895e014fee2a120ac8d3c9e7/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container ba501807a65e\n",
      " ---> d9d219a4e066\n",
      "Step 25/28 : ENV MLFLOW_DISABLE_ENV_CREATION=\"true\"\n",
      " ---> Running in e657b3f8db12\n",
      "Removing intermediate container e657b3f8db12\n",
      " ---> 67f00004b3e5\n",
      "Step 26/28 : ENV ENABLE_MLSERVER=False\n",
      " ---> Running in 55c8cee90a05\n",
      "Removing intermediate container 55c8cee90a05\n",
      " ---> 47d366448ddc\n",
      "Step 27/28 : RUN chmod o+rwX /opt/mlflow/\n",
      " ---> Running in 1eefd8664518\n",
      "Removing intermediate container 1eefd8664518\n",
      " ---> 82ef453de82d\n",
      "Step 28/28 : ENTRYPOINT [\"python\", \"-c\", \"from mlflow.models import container as C;C._serve('virtualenv')\"]\n",
      " ---> Running in fca363b632a4\n",
      "Removing intermediate container fca363b632a4\n",
      " ---> dbf0cd3b52f2\n",
      "Successfully built dbf0cd3b52f2\n",
      "Successfully tagged arima-image:latest\n"
     ]
    }
   ],
   "source": [
    "mlflow.models.build_docker(f\"models:/ARIMA/{version}\", name='arima-image')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
